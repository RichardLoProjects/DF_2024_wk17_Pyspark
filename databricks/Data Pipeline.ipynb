{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d00fd73b-9249-45fb-9147-c627daaa3629",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "java.io.IOException: Connection failed\n",
       "\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:848)\n",
       "\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:775)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:275)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:247)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:164)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:821)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:559)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:313)\n",
       "\tat com.databricks.rpc.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:161)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n",
       "\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1671)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:660)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:966)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:369)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1700(ManagedSelector.java:65)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:676)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:535)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:173)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:279)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:275)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:125)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$3(InstrumentedQueuedThreadPool.scala:173)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:125)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:167)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
       "Caused by: java.net.ConnectException: Connection refused\n",
       "\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
       "\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:347)\n",
       "\t... 26 more"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "java.io.IOException: Connection failed\n\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:848)\n\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:775)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:275)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:247)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:164)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:821)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:559)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:313)\n\tat com.databricks.rpc.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:161)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1671)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:660)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:966)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:369)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1700(ManagedSelector.java:65)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:676)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:535)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:173)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:279)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:275)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:125)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$3(InstrumentedQueuedThreadPool.scala:173)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:125)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:167)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.net.ConnectException: Connection refused\n\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:347)\n\t... 26 more\n",
       "errorSummary": "Internal error. Attach your notebook to a different compute or restart the current compute.",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.types import (\n",
    "    StructField\n",
    "    , StringType\n",
    "    , IntegerType\n",
    "    , DoubleType\n",
    "    , StructType\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffef5cee-fb9c-4047-b285-aa743efde874",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "java.io.IOException: Connection failed\n",
       "\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:848)\n",
       "\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:775)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:275)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:247)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:164)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:821)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:559)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:313)\n",
       "\tat com.databricks.rpc.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:161)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n",
       "\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1671)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:660)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:966)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:369)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1700(ManagedSelector.java:65)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:676)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:535)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:173)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:279)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:275)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:125)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$3(InstrumentedQueuedThreadPool.scala:173)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:125)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:167)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
       "Caused by: java.net.ConnectException: Connection refused\n",
       "\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
       "\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:347)\n",
       "\t... 26 more"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "java.io.IOException: Connection failed\n\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:848)\n\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:775)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:275)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:247)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:164)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:821)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:559)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:313)\n\tat com.databricks.rpc.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:161)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1671)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:660)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:966)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:369)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1700(ManagedSelector.java:65)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:676)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:535)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:173)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:279)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:275)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:125)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$3(InstrumentedQueuedThreadPool.scala:173)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:125)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:167)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.net.ConnectException: Connection refused\n\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:347)\n\t... 26 more\n",
       "errorSummary": "Internal error. Attach your notebook to a different compute or restart the current compute.",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DataPipeline:\n",
    "    def __init__(\n",
    "            self\n",
    "            , spark:SparkSession\n",
    "        ) -> None:\n",
    "        self.spark = spark\n",
    "        self.file_paths:dict = {\n",
    "            'test.csv':\"/FileStore/tables/test.csv\"\n",
    "            , 'train.csv':\"/FileStore/tables/train.csv\"\n",
    "            , 'Customer_Churn_Records.csv':\"/FileStore/tables/Customer_Churn_Records.csv\"\n",
    "            , 'Bank_Customer_Churn_Prediction.csv':\"/FileStore/tables/Bank_Customer_Churn_Prediction.csv\"\n",
    "            , 'Churn_Modeling.csv':\"/FileStore/tables/Churn_Modeling.csv\"\n",
    "            , 'Churn_Modelling.csv':\"/FileStore/tables/Churn_Modelling.csv\"\n",
    "            , 'Churn_Modelling-1.csv':\"/FileStore/tables/Churn_Modelling-1.csv\"\n",
    "            , 'churn.csv':\"/FileStore/tables/churn.csv\"\n",
    "        }\n",
    "        self.spark_dataframes = None\n",
    "        self.joined_df = None\n",
    "        self.target_df = None\n",
    "    def run(self) -> None:\n",
    "        self.extract()\n",
    "        self.transform()\n",
    "        self.load()\n",
    "    def extract(self) -> None:\n",
    "        self._extract()\n",
    "    def transform(self) -> None:\n",
    "        self._transform_create_target_table()\n",
    "        self._transform_rename_columns()\n",
    "        self._transform_remove_null_id()\n",
    "        self._transform_assert_unique_id()\n",
    "        self._transform_full_outer_join()\n",
    "        self._transform_data_validation()\n",
    "    def load(self) -> None:\n",
    "        #save to train csv and test csv OR save to 1 csv and ML pipieline breaks into train-test split\n",
    "        pass\n",
    "    def _extract(self) -> None:\n",
    "        self.spark_dataframes = dict()\n",
    "        self.spark_dataframes['test.csv'] = self.spark.read.csv(\n",
    "            self.file_paths['test.csv']\n",
    "            , header=True\n",
    "            , schema=StructType(fields=[\n",
    "                StructField('id', IntegerType(), True)\n",
    "                , StructField('CustomerId', IntegerType(), True)\n",
    "                , StructField('Surname', StringType(), True)\n",
    "                , StructField('CreditScore', IntegerType(), True)\n",
    "                , StructField('Geography', StringType(), True)\n",
    "                , StructField('Gender', StringType(), True)\n",
    "                , StructField('Age', IntegerType(), True)\n",
    "                , StructField('Tenure', IntegerType(), True)\n",
    "                , StructField('Balance', DoubleType(), True)\n",
    "                , StructField('NumOfProducts', IntegerType(), True)\n",
    "                , StructField('HasCrCard', IntegerType(), True)\n",
    "                , StructField('IsActiveMember', IntegerType(), True)\n",
    "                , StructField('EstimatedSalary', DoubleType(), True)\n",
    "            ])\n",
    "        )\n",
    "        self.spark_dataframes['train.csv'] = self.spark.read.csv(\n",
    "            self.file_paths['train.csv']\n",
    "            , header=True\n",
    "            , schema=StructType(fields=[\n",
    "                StructField('id', IntegerType(), True)\n",
    "                , StructField('CustomerId', IntegerType(), True)\n",
    "                , StructField('Surname', StringType(), True)\n",
    "                , StructField('CreditScore', IntegerType(), True)\n",
    "                , StructField('Geography', StringType(), True)\n",
    "                , StructField('Gender', StringType(), True)\n",
    "                , StructField('Age', IntegerType(), True)\n",
    "                , StructField('Tenure', IntegerType(), True)\n",
    "                , StructField('Balance', DoubleType(), True)\n",
    "                , StructField('NumOfProducts', IntegerType(), True)\n",
    "                , StructField('HasCrCard', IntegerType(), True)\n",
    "                , StructField('IsActiveMember', IntegerType(), True)\n",
    "                , StructField('EstimatedSalary', DoubleType(), True)\n",
    "                , StructField('Exited', IntegerType(), True)\n",
    "            ])\n",
    "        )\n",
    "        self.spark_dataframes['Customer_Churn_Records.csv'] = self.spark.read.csv(\n",
    "            self.file_paths['Customer_Churn_Records.csv']\n",
    "            , header=True\n",
    "            , schema=StructType(fields=[\n",
    "                StructField('RowNumber', IntegerType(), True)\n",
    "                , StructField('CustomerId', IntegerType(), True)\n",
    "                , StructField('Surname', StringType(), True)\n",
    "                , StructField('CreditScore', IntegerType(), True)\n",
    "                , StructField('Geography', StringType(), True)\n",
    "                , StructField('Gender', StringType(), True)\n",
    "                , StructField('Age', IntegerType(), True)\n",
    "                , StructField('Tenure', IntegerType(), True)\n",
    "                , StructField('Balance', DoubleType(), True)\n",
    "                , StructField('NumOfProducts', IntegerType(), True)\n",
    "                , StructField('HasCrCard', IntegerType(), True)\n",
    "                , StructField('IsActiveMember', IntegerType(), True)\n",
    "                , StructField('EstimatedSalary', DoubleType(), True)\n",
    "                , StructField('Exited', IntegerType(), True)\n",
    "                , StructField('Complain', IntegerType(), True)\n",
    "                , StructField('Satisfaction Score', IntegerType(), True)\n",
    "                , StructField('Card Type', StringType(), True)\n",
    "                , StructField('Point Earned', IntegerType(), True)\n",
    "            ])\n",
    "        )\n",
    "        self.spark_dataframes['Bank_Customer_Churn_Prediction.csv'] = self.spark.read.csv(\n",
    "            self.file_paths['Bank_Customer_Churn_Prediction.csv']\n",
    "            , header=True\n",
    "            , schema=StructType(fields=[\n",
    "                StructField('customer_id', IntegerType(), True)\n",
    "                , StructField('credit_score', IntegerType(), True)\n",
    "                , StructField('country', StringType(), True)\n",
    "                , StructField('gender', StringType(), True)\n",
    "                , StructField('age', IntegerType(), True)\n",
    "                , StructField('tenure', IntegerType(), True)\n",
    "                , StructField('balance', DoubleType(), True)\n",
    "                , StructField('products_number', IntegerType(), True)\n",
    "                , StructField('credit_card', IntegerType(), True)\n",
    "                , StructField('active_member', IntegerType(), True)\n",
    "                , StructField('estimated_salary', DoubleType(), True)\n",
    "                , StructField('churn', IntegerType(), True)\n",
    "            ])\n",
    "        )\n",
    "        self.spark_dataframes['Churn_Modeling.csv'] = self.spark.read.csv(\n",
    "            self.file_paths['Churn_Modeling.csv']\n",
    "            , header=True\n",
    "            , schema=StructType(fields=[\n",
    "                StructField('RowNumber', IntegerType(), True)\n",
    "                , StructField('CustomerId', IntegerType(), True)\n",
    "                , StructField('Surname', StringType(), True)\n",
    "                , StructField('CreditScore', IntegerType(), True)\n",
    "                , StructField('Geography', StringType(), True)\n",
    "                , StructField('Gender', StringType(), True)\n",
    "                , StructField('Age', IntegerType(), True)\n",
    "                , StructField('Tenure', IntegerType(), True)\n",
    "                , StructField('Balance', DoubleType(), True)\n",
    "                , StructField('NumOfProducts', IntegerType(), True)\n",
    "                , StructField('HasCrCard', IntegerType(), True)\n",
    "                , StructField('IsActiveMember', IntegerType(), True)\n",
    "                , StructField('EstimatedSalary', DoubleType(), True)\n",
    "                , StructField('Exited', IntegerType(), True)\n",
    "            ])\n",
    "        )\n",
    "        self.spark_dataframes['Churn_Modelling.csv'] = self.spark.read.csv(\n",
    "            self.file_paths['Churn_Modelling.csv']\n",
    "            , header=True\n",
    "            , schema=StructType(fields=[\n",
    "                StructField('RowNumber', IntegerType(), True)\n",
    "                , StructField('CustomerId', IntegerType(), True)\n",
    "                , StructField('Surname', StringType(), True)\n",
    "                , StructField('CreditScore', IntegerType(), True)\n",
    "                , StructField('Geography', StringType(), True)\n",
    "                , StructField('Gender', StringType(), True)\n",
    "                , StructField('Age', IntegerType(), True)\n",
    "                , StructField('Tenure', IntegerType(), True)\n",
    "                , StructField('Balance', DoubleType(), True)\n",
    "                , StructField('NumOfProducts', IntegerType(), True)\n",
    "                , StructField('HasCrCard', IntegerType(), True)\n",
    "                , StructField('IsActiveMember', IntegerType(), True)\n",
    "                , StructField('EstimatedSalary', DoubleType(), True)\n",
    "                , StructField('Exited', IntegerType(), True)\n",
    "            ])\n",
    "        )\n",
    "        self.spark_dataframes['Churn_Modelling-1.csv'] = self.spark.read.csv(\n",
    "            self.file_paths['Churn_Modelling-1.csv']\n",
    "            , header=True\n",
    "            , schema=StructType(fields=[\n",
    "                StructField('RowNumber', IntegerType(), True)\n",
    "                , StructField('CustomerId', IntegerType(), True)\n",
    "                , StructField('Surname', StringType(), True)\n",
    "                , StructField('CreditScore', IntegerType(), True)\n",
    "                , StructField('Geography', StringType(), True)\n",
    "                , StructField('Gender', StringType(), True)\n",
    "                , StructField('Age', IntegerType(), True)\n",
    "                , StructField('Tenure', IntegerType(), True)\n",
    "                , StructField('Balance', DoubleType(), True)\n",
    "                , StructField('NumOfProducts', IntegerType(), True)\n",
    "                , StructField('HasCrCard', IntegerType(), True)\n",
    "                , StructField('IsActiveMember', IntegerType(), True)\n",
    "                , StructField('EstimatedSalary', DoubleType(), True)\n",
    "                , StructField('Exited', IntegerType(), True)\n",
    "            ])\n",
    "        )\n",
    "        self.spark_dataframes['churn.csv'] = self.spark.read.csv(\n",
    "            self.file_paths['churn.csv']\n",
    "            , header=True\n",
    "            , schema=StructType(fields=[\n",
    "                StructField('RowNumber', IntegerType(), True)\n",
    "                , StructField('CustomerId', IntegerType(), True)\n",
    "                , StructField('Surname', StringType(), True)\n",
    "                , StructField('CreditScore', IntegerType(), True)\n",
    "                , StructField('Geography', StringType(), True)\n",
    "                , StructField('Gender', StringType(), True)\n",
    "                , StructField('Age', IntegerType(), True)\n",
    "                , StructField('Tenure', IntegerType(), True)\n",
    "                , StructField('Balance', DoubleType(), True)\n",
    "                , StructField('NumOfProducts', IntegerType(), True)\n",
    "                , StructField('HasCrCard', IntegerType(), True)\n",
    "                , StructField('IsActiveMember', IntegerType(), True)\n",
    "                , StructField('EstimatedSalary', DoubleType(), True)\n",
    "                , StructField('Exited', IntegerType(), True)\n",
    "            ])\n",
    "        )\n",
    "    def _transform_create_target_table(self) -> None:\n",
    "        self.target_df = spark.createDataFrame([], schema=StructType(fields=[\n",
    "            StructField('customer_id', IntegerType(), True)\n",
    "            , StructField('surname', StringType(), True)\n",
    "            , StructField('credit_score', IntegerType(), True)\n",
    "            , StructField('geography', StringType(), True)\n",
    "            , StructField('gender', StringType(), True)\n",
    "            , StructField('age', IntegerType(), True)\n",
    "            , StructField('tenure', IntegerType(), True)\n",
    "            , StructField('balance', DoubleType(), True)\n",
    "            , StructField('product_count', IntegerType(), True)\n",
    "            , StructField('has_creditcard', IntegerType(), True)\n",
    "            , StructField('active_member', IntegerType(), True)\n",
    "            , StructField('estimated_salary', DoubleType(), True)\n",
    "            , StructField('complain', IntegerType(), True)\n",
    "            , StructField('satisfaction_score', IntegerType(), True)\n",
    "            , StructField('card_type', StringType(), True)\n",
    "            , StructField('points_earned', IntegerType(), True)\n",
    "            , StructField('churn', IntegerType(), True)\n",
    "        ]))\n",
    "    def _transform_rename_columns(self) -> None:\n",
    "        new_column_names = [\n",
    "            'id_test_csv'\n",
    "            , 'customer_id'\n",
    "            , 'surname_test_csv'\n",
    "            , 'credit_score_test_csv'\n",
    "            , 'geography_test_csv'\n",
    "            , 'gender_test_csv'\n",
    "            , 'age_test_csv'\n",
    "            , 'tenure_test_csv'\n",
    "            , 'balance_test_csv'\n",
    "            , 'product_count_test_csv'\n",
    "            , 'has_creditcard_test_csv'\n",
    "            , 'active_member_test_csv'\n",
    "            , 'estimated_salary_test_csv'\n",
    "        ]\n",
    "        self.spark_dataframes['test.csv'] = self.spark_dataframes['test.csv'].toDF(*new_column_names)\n",
    "        new_column_names = [\n",
    "            'id_train_csv'\n",
    "            , 'customer_id'\n",
    "            , 'surname_train_csv'\n",
    "            , 'credit_score_train_csv'\n",
    "            , 'geography_train_csv'\n",
    "            , 'gender_train_csv'\n",
    "            , 'age_train_csv'\n",
    "            , 'tenure_train_csv'\n",
    "            , 'balance_train_csv'\n",
    "            , 'product_count_train_csv'\n",
    "            , 'has_creditcard_train_csv'\n",
    "            , 'active_member_train_csv'\n",
    "            , 'estimated_salary_train_csv'\n",
    "            , 'churn_train_csv'\n",
    "        ]\n",
    "        self.spark_dataframes['train.csv'] = self.spark_dataframes['train.csv'].toDF(*new_column_names)\n",
    "        new_column_names = [\n",
    "            'rownum_Customer_Churn_Records_csv'\n",
    "            , 'customer_id'\n",
    "            , 'surname_Customer_Churn_Records_csv'\n",
    "            , 'credit_score_Customer_Churn_Records_csv'\n",
    "            , 'geography_Customer_Churn_Records_csv'\n",
    "            , 'gender_Customer_Churn_Records_csv'\n",
    "            , 'age_Customer_Churn_Records_csv'\n",
    "            , 'tenure_Customer_Churn_Records_csv'\n",
    "            , 'balance_Customer_Churn_Records_csv'\n",
    "            , 'product_count_Customer_Churn_Records_csv'\n",
    "            , 'has_creditcard_Customer_Churn_Records_csv'\n",
    "            , 'active_member_Customer_Churn_Records_csv'\n",
    "            , 'estimated_salary_Customer_Churn_Records_csv'\n",
    "            , 'churn_Customer_Churn_Records_csv'\n",
    "            , 'complain_Customer_Churn_Records_csv'\n",
    "            , 'satisfaction_score_Customer_Churn_Records_csv'\n",
    "            , 'card_type_Customer_Churn_Records_csv'\n",
    "            , 'points_earned_Customer_Churn_Records_csv'\n",
    "        ]\n",
    "        self.spark_dataframes['Customer_Churn_Records.csv'] = \\\n",
    "            self.spark_dataframes['Customer_Churn_Records.csv'].toDF(*new_column_names)\n",
    "        new_column_names = [\n",
    "            'customer_id'\n",
    "            , 'credit_score_Bank_Customer_Churn_Prediction_csv'\n",
    "            , 'geography_Bank_Customer_Churn_Prediction_csv'\n",
    "            , 'gender_Bank_Customer_Churn_Prediction_csv'\n",
    "            , 'age_Bank_Customer_Churn_Prediction_csv'\n",
    "            , 'tenure_Bank_Customer_Churn_Prediction_csv'\n",
    "            , 'balance_Bank_Customer_Churn_Prediction_csv'\n",
    "            , 'product_count_Bank_Customer_Churn_Prediction_csv'\n",
    "            , 'has_creditcard_Bank_Customer_Churn_Prediction_csv'\n",
    "            , 'active_member_Bank_Customer_Churn_Prediction_csv'\n",
    "            , 'estimated_salary_Bank_Customer_Churn_Prediction_csv'\n",
    "            , 'churn_Bank_Customer_Churn_Prediction_csv'\n",
    "        ]\n",
    "        self.spark_dataframes['Bank_Customer_Churn_Prediction.csv'] = \\\n",
    "            self.spark_dataframes['Bank_Customer_Churn_Prediction.csv'].toDF(*new_column_names)\n",
    "        new_column_names = [\n",
    "            'rownum_Churn_Modeling_csv'\n",
    "            , 'customer_id'\n",
    "            , 'surname_Churn_Modeling_csv'\n",
    "            , 'credit_score_Churn_Modeling_csv'\n",
    "            , 'geography_Churn_Modeling_csv'\n",
    "            , 'gender_Churn_Modeling_csv'\n",
    "            , 'age_Churn_Modeling_csv'\n",
    "            , 'tenure_Churn_Modeling_csv'\n",
    "            , 'balance_Churn_Modeling_csv'\n",
    "            , 'product_count_Churn_Modeling_csv'\n",
    "            , 'has_creditcard_Churn_Modeling_csv'\n",
    "            , 'active_member_Churn_Modeling_csv'\n",
    "            , 'estimated_salary_Churn_Modeling_csv'\n",
    "            , 'churn_Churn_Modeling_csv'\n",
    "        ]\n",
    "        self.spark_dataframes['Churn_Modeling.csv'] = \\\n",
    "            self.spark_dataframes['Churn_Modeling.csv'].toDF(*new_column_names)\n",
    "        new_column_names = [\n",
    "            'rownum_Churn_Modelling_csv'\n",
    "            , 'customer_id'\n",
    "            , 'surname_Churn_Modelling_csv'\n",
    "            , 'credit_score_Churn_Modelling_csv'\n",
    "            , 'geography_Churn_Modelling_csv'\n",
    "            , 'gender_Churn_Modelling_csv'\n",
    "            , 'age_Churn_Modelling_csv'\n",
    "            , 'tenure_Churn_Modelling_csv'\n",
    "            , 'balance_Churn_Modelling_csv'\n",
    "            , 'product_count_Churn_Modelling_csv'\n",
    "            , 'has_creditcard_Churn_Modelling_csv'\n",
    "            , 'active_member_Churn_Modelling_csv'\n",
    "            , 'estimated_salary_Churn_Modelling_csv'\n",
    "            , 'churn_Churn_Modelling_csv'\n",
    "        ]\n",
    "        self.spark_dataframes['Churn_Modelling.csv'] = \\\n",
    "            self.spark_dataframes['Churn_Modelling.csv'].toDF(*new_column_names)\n",
    "        new_column_names = [\n",
    "            'rownum_Churn_Modelling-1_csv'\n",
    "            , 'customer_id'\n",
    "            , 'surname_Churn_Modelling-1_csv'\n",
    "            , 'credit_score_Churn_Modelling-1_csv'\n",
    "            , 'geography_Churn_Modelling-1_csv'\n",
    "            , 'gender_Churn_Modelling-1_csv'\n",
    "            , 'age_Churn_Modelling-1_csv'\n",
    "            , 'tenure_Churn_Modelling-1_csv'\n",
    "            , 'balance_Churn_Modelling-1_csv'\n",
    "            , 'product_count_Churn_Modelling-1_csv'\n",
    "            , 'has_creditcard_Churn_Modelling-1_csv'\n",
    "            , 'active_member_Churn_Modelling-1_csv'\n",
    "            , 'estimated_salary_Churn_Modelling-1_csv'\n",
    "            , 'churn_Churn_Modelling-1_csv'\n",
    "        ]\n",
    "        self.spark_dataframes['Churn_Modelling-1.csv'] = \\\n",
    "            self.spark_dataframes['Churn_Modelling-1.csv'].toDF(*new_column_names)\n",
    "        new_column_names = [\n",
    "            'rownum_churn_csv'\n",
    "            , 'customer_id'\n",
    "            , 'surname_churn_csv'\n",
    "            , 'credit_score_churn_csv'\n",
    "            , 'geography_churn_csv'\n",
    "            , 'gender_churn_csv'\n",
    "            , 'age_churn_csv'\n",
    "            , 'tenure_churn_csv'\n",
    "            , 'balance_churn_csv'\n",
    "            , 'product_count_churn_csv'\n",
    "            , 'has_creditcard_churn_csv'\n",
    "            , 'active_member_churn_csv'\n",
    "            , 'estimated_salary_churn_csv'\n",
    "            , 'churn_churn_csv'\n",
    "        ]\n",
    "        self.spark_dataframes['churn.csv'] = self.spark_dataframes['churn.csv'].toDF(*new_column_names)\n",
    "    def _transform_remove_null_id(self) -> None:\n",
    "        self.spark_dataframes = \\\n",
    "            {k:df.filter(df.customer_id.isNotNull()) for k,df in self.spark_dataframes.copy().items()}\n",
    "    def _transform_assert_unique_id(self) -> None:\n",
    "        self.spark_dataframes = \\\n",
    "            {k:df.dropDuplicates(['customer_id']) for k,df in self.spark_dataframes.copy().items()}\n",
    "        for df in self.spark_dataframes.values():\n",
    "            dupe_count = df.groupBy('customer_id').count().filter('count > 1').count()\n",
    "            assert dupe_count == 0, 'duplicates in the df'\n",
    "    def _transform_full_outer_join(self) -> None:\n",
    "        ordered_df = [df for df in self.spark_dataframes.values()]\n",
    "        self.joined_df = ordered_df[0]\n",
    "        for df in ordered_df[1:]:\n",
    "            self.joined_df = self.joined_df.join(df, on='customer_id', how='full')\n",
    "    def _transform_data_validation(self) -> None:\n",
    "        all_cust_id = set(r[0] for r in self.joined_df.collect())\n",
    "        _db_number = len(all_cust_id)\n",
    "        _db_count = 0\n",
    "        _db_percent = _db_number // 100\n",
    "        _db_prog = 0\n",
    "        print(_db_number)\n",
    "        for cust_id in all_cust_id:\n",
    "            print(1)\n",
    "            cust = self.joined_df.filter(self.joined_df.customer_id == cust_id)\n",
    "            print(2)\n",
    "            valid = True\n",
    "            cust_data = []\n",
    "            for column_name in self.target_df.columns:\n",
    "                columns = [c for c in self.joined_df.columns if column_name in c]\n",
    "                values = set(v for v in cust.select(columns).first())\n",
    "                values.add(None)\n",
    "                if len(values) > 2:\n",
    "                    valid = False\n",
    "                elif len(values) == 2:\n",
    "                    cust_data.append([v for v in values if v != None][0])\n",
    "                elif len(values) == 1:\n",
    "                    cust_data.append(None)\n",
    "            print(3)\n",
    "            if valid:\n",
    "                self.target_df = self.target_df.union(spark.createDataFrame(\n",
    "                    [tuple(cust_data)]\n",
    "                    , schema=self.target_df.schema\n",
    "                ))\n",
    "            _db_count += 1\n",
    "            if _db_count == _db_percent:\n",
    "                _db_count = 0\n",
    "                _db_prog += 1\n",
    "                print(f'{_db_prog}, ', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e83ef32e-96fd-420b-818b-13135d6a3065",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "java.io.IOException: Connection failed\n",
       "\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:848)\n",
       "\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:775)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:275)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:247)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:164)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:821)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:559)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:313)\n",
       "\tat com.databricks.rpc.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:161)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n",
       "\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1671)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:660)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:966)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:369)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1700(ManagedSelector.java:65)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:676)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:535)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:173)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:279)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:275)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:125)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$3(InstrumentedQueuedThreadPool.scala:173)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:125)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:167)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
       "Caused by: java.net.ConnectException: Connection refused\n",
       "\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
       "\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:347)\n",
       "\t... 26 more"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "java.io.IOException: Connection failed\n\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:848)\n\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:775)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:275)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:247)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:164)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:821)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:559)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:313)\n\tat com.databricks.rpc.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:161)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1671)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:660)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:966)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:369)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1700(ManagedSelector.java:65)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:676)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:535)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:173)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:279)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:275)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:125)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$3(InstrumentedQueuedThreadPool.scala:173)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:125)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:167)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.net.ConnectException: Connection refused\n\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:347)\n\t... 26 more\n",
       "errorSummary": "Internal error. Attach your notebook to a different compute or restart the current compute.",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ignore_comment = '''\n",
    "test = use for prediction (they have no labels)\n",
    "\n",
    "rest of data merge and run 70:30 split\n",
    "\ttrain id = RowNumber (i might just drop these columns and reset them tbh)\n",
    "\t18col = same + 4more\n",
    "\tsnek_case = total rename (also they only have 12 columns) (missing rownum and surname)\n",
    " \n",
    "BASE 14 COLUMNS\n",
    "    RowNumber (id - train.csv, not in snekcase)\n",
    "    CustomerId\n",
    "    Surname (not in snekcase)\n",
    "    CreditScore\n",
    "    Geography (country)\n",
    "    Gender\n",
    "    Age\n",
    "    Tenure\n",
    "    Balance\n",
    "    NumOfProducts (products_number)\n",
    "    HasCrCard (credit_card)\n",
    "    IsActiveMember (active_member)\n",
    "    EstimatedSalary\n",
    "    Exited (churn)\n",
    "\n",
    "\n",
    "\n",
    "df_renamed = df.withColumnRenamed(\"age\", \"user_age\")\n",
    "columns = [\"name\", \"age\", \"city\"]\n",
    "df_reordered = df.select(\"city\", \"name\", \"age\")\n",
    "\n",
    "new_column_names = [\n",
    "    \"CustomerId\"\n",
    "    , \"CreditScore\"\n",
    "    , \"Geography\"\n",
    "    , \"Gender\"\n",
    "    , \"Age\"\n",
    "    , \"Tenure\"\n",
    "    , \"Balance\"\n",
    "    , \"NumOfProducts\"\n",
    "    , \"HasCrCard\"\n",
    "    , \"IsActiveMember\"\n",
    "    , \"EstimatedSalary\"\n",
    "    , \"Exited\"\n",
    "]\n",
    "df_renamed = df.toDF(*new_column_names)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b393b54-dc81-4141-a52c-90102c0ab5fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "java.io.IOException: Connection failed\n",
       "\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:848)\n",
       "\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:775)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:275)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:247)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:164)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:821)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:559)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:313)\n",
       "\tat com.databricks.rpc.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:161)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n",
       "\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1671)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:660)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:966)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:369)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1700(ManagedSelector.java:65)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:676)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:535)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:173)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:279)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:275)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:125)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$3(InstrumentedQueuedThreadPool.scala:173)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:125)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:167)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
       "Caused by: java.net.ConnectException: Connection refused\n",
       "\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
       "\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:347)\n",
       "\t... 26 more"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "java.io.IOException: Connection failed\n\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:848)\n\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:775)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:275)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:247)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:164)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:821)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:559)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:313)\n\tat com.databricks.rpc.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:161)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1671)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:660)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:966)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:369)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1700(ManagedSelector.java:65)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:676)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:535)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:173)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:279)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:275)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:125)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$3(InstrumentedQueuedThreadPool.scala:173)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:125)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:167)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.net.ConnectException: Connection refused\n\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:347)\n\t... 26 more\n",
       "errorSummary": "Internal error. Attach your notebook to a different compute or restart the current compute.",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main() -> None:\n",
    "    spark = SparkSession.builder.appName(\"Data_Pipeline\").getOrCreate()\n",
    "    pipeline = DataPipeline(spark)\n",
    "    pipeline.run()\n",
    "    print('Script ran without crashing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "087fcd4e-24ee-49ff-ab75-3fc20e470ff1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "java.io.IOException: Connection failed\n",
       "\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:848)\n",
       "\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:775)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:275)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:247)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:164)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:821)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:559)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:313)\n",
       "\tat com.databricks.rpc.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:161)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n",
       "\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1671)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:660)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:966)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:369)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1700(ManagedSelector.java:65)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:676)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:535)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:173)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:279)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:275)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:125)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$3(InstrumentedQueuedThreadPool.scala:173)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:125)\n",
       "\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:167)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
       "Caused by: java.net.ConnectException: Connection refused\n",
       "\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
       "\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n",
       "\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:347)\n",
       "\t... 26 more"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "java.io.IOException: Connection failed\n\tat com.databricks.rpc.Jetty9Client$$anon$1.handleError(Jetty9Client.scala:848)\n\tat com.databricks.rpc.Jetty9Client$$anon$1.onFailure(Jetty9Client.scala:775)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:197)\n\tat shaded.v9_4.org.eclipse.jetty.client.ResponseNotifier.notifyFailure(ResponseNotifier.java:189)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.notifyFailureComplete(HttpExchange.java:275)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpExchange.abort(HttpExchange.java:247)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpConversation.abort(HttpConversation.java:164)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpRequest.abort(HttpRequest.java:821)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.abort(HttpDestination.java:559)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpDestination.failed(HttpDestination.java:313)\n\tat com.databricks.rpc.AbstractConnectionPool$1.failed(AbstractConnectionPool.java:161)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat com.databricks.rpc.Jetty9Client$DatabricksHttpDestinationOverHTTP$$anon$2.failed(Jetty9Client.scala:1671)\n\tat shaded.v9_4.org.eclipse.jetty.util.Promise$Wrapper.failed(Promise.java:136)\n\tat shaded.v9_4.org.eclipse.jetty.client.HttpClient$1$1.failed(HttpClient.java:660)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport.connectFailed(AbstractConnectorHttpClientTransport.java:138)\n\tat shaded.v9_4.org.eclipse.jetty.client.AbstractConnectorHttpClientTransport$ClientSelectorManager.connectionFailed(AbstractConnectorHttpClientTransport.java:188)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$Connect.failed(ManagedSelector.java:966)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:369)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.access$1700(ManagedSelector.java:65)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.processSelected(ManagedSelector.java:676)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:535)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:173)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:279)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:275)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:125)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.$anonfun$run$3(InstrumentedQueuedThreadPool.scala:173)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:125)\n\tat com.databricks.rpc.ShadedInstrumentedQueuedThreadPool$$anon$2.run(InstrumentedQueuedThreadPool.scala:167)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n\tat shaded.v9_4.org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.net.ConnectException: Connection refused\n\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n\tat shaded.v9_4.org.eclipse.jetty.io.SelectorManager.doFinishConnect(SelectorManager.java:355)\n\tat shaded.v9_4.org.eclipse.jetty.io.ManagedSelector.processConnect(ManagedSelector.java:347)\n\t... 26 more\n",
       "errorSummary": "Internal error. Attach your notebook to a different compute or restart the current compute.",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Data Pipeline",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
