{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e0daeb4-fcc9-4c16-a1c9-232f17adbfd5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Data Integration Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e02b0615-e539-4475-bd63-d367059fdf26",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql import SparkSession, Row, functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StructField\n",
    "    , StringType\n",
    "    , IntegerType\n",
    "    , DoubleType\n",
    "    , BooleanType\n",
    "    , StructType\n",
    ")\n",
    "spark = SparkSession.builder.appName(\"Pipeline_Test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc68e9bf-9d4c-482a-a2dc-16a2083b60ac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Aims\n",
    "\n",
    "The goal is to seek an algorithmic approach to merging the following datasets where the column names are implicitly defined based on domain knowledge and EDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "187873bf-170d-4b5e-9598-bb1d3fb4a214",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset_A = {\n",
    "    1: (1769, 6421.79, 0, 'Dave', 30)\n",
    "    , 2: (8341, 1137.20, 1, 'Bob', 42)\n",
    "    , 3: (4507, 911.93, 0, 'Jess', 21)\n",
    "    , 4: (None, 1234.0, 0, 'Lisa', 37)\n",
    "    , 5: (4405, 7891.37, None, 'Andy', 38)\n",
    "    , 6: (6666, 1234.0, 0, None, 99)\n",
    "}\n",
    "\n",
    "dataset_B = {\n",
    "    0: (1769, 30, 6421.79, 0, None)\n",
    "    , 1: (4507, 21, 911.93, 0, 48)\n",
    "    , 2: (4405, 38, 7891.37, 1, 587)\n",
    "    , 3: (8341, 42, 10.56, 1, 999)\n",
    "    , 4: (7777, 56, 4939.32, None, 1233)\n",
    "    , 5: (6666, 98, 1234.0, 0, 1234)\n",
    "}\n",
    "\n",
    "dataset_C = {\n",
    "    4232: (None, 58.58, 23)\n",
    "    , 9947: (687, 3400.21, 66)\n",
    "    , 8888: (951, 78.29, 18)\n",
    "    , 6666: (543, 435.0, 97)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b59579d6-d307-4f7c-9c05-bc70dddd7fad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Step 0\n",
    "\n",
    "A target for the data is set based off EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ef3bb8e-08cd-4323-b864-c2674cd47444",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- cust_id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- age: integer (nullable = true)\n |-- balance: double (nullable = true)\n |-- c_score: integer (nullable = true)\n |-- churn: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "target_df = spark.createDataFrame([], schema=StructType(fields=[\n",
    "    StructField('cust_id', IntegerType(), True)\n",
    "    , StructField('name', StringType(), True)\n",
    "    , StructField('age', IntegerType(), True)\n",
    "    , StructField('balance', DoubleType(), True)\n",
    "    , StructField('c_score', IntegerType(), True)\n",
    "    , StructField('churn', IntegerType(), True)\n",
    "]))\n",
    "target_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3fd51be-8c36-4c39-81f6-25a3c655b00b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Step 1\n",
    "\n",
    "It is assumed\n",
    "- `cust_id` is consistent across all datasets.\n",
    "- all datasets have similar data: ie the columns are somewhat the same.\n",
    "- the schemas are roughly compatible: eg age is numeric instead of a mix of string/numeric.\n",
    "\n",
    "Each dataframe attribute is labeled according to the data because it is not assumed that the data is consistent. Care must be taken to validate consistency when merging multiple data sources into the target table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "753a7fc2-982a-4b5a-9d95-14f47794de94",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_A = spark.createDataFrame([\n",
    "    Row(\n",
    "        idx=i\n",
    "        , cust_id=r[0]\n",
    "        , balance_A=r[1]\n",
    "        , churn_A=r[2]\n",
    "        , name_A=r[3]\n",
    "        , age_A=r[4]\n",
    "    ) for i,r in dataset_A.items()\n",
    "])\n",
    "\n",
    "df_B = spark.createDataFrame([\n",
    "    Row(\n",
    "        idx=i\n",
    "        , cust_id=r[0]\n",
    "        , age_B=r[1]\n",
    "        , balance_B=r[2]\n",
    "        , churn_B=r[3]\n",
    "        , c_score_B=r[4]\n",
    "    ) for i,r in dataset_B.items()\n",
    "])\n",
    "\n",
    "df_C = spark.createDataFrame([\n",
    "    Row(\n",
    "        cust_id=i\n",
    "        , c_score_C=r[0]\n",
    "        , balance_C=r[1]\n",
    "        , age_C=r[2]\n",
    "    ) for i,r in dataset_C.items()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b93d74b3-c31c-45b4-8325-ee70492dfbff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---------+-------+------+-----+\n|idx|cust_id|balance_A|churn_A|name_A|age_A|\n+---+-------+---------+-------+------+-----+\n|  1|   1769|  6421.79|      0|  Dave|   30|\n|  2|   8341|   1137.2|      1|   Bob|   42|\n|  3|   4507|   911.93|      0|  Jess|   21|\n|  4|   null|   1234.0|      0|  Lisa|   37|\n|  5|   4405|  7891.37|   null|  Andy|   38|\n|  6|   6666|   1234.0|      0|  null|   99|\n+---+-------+---------+-------+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df_A.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff4ba10c-5ffd-4d0c-83b1-7d26bc91ac94",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+---------+-------+---------+\n|idx|cust_id|age_B|balance_B|churn_B|c_score_B|\n+---+-------+-----+---------+-------+---------+\n|  0|   1769|   30|  6421.79|      0|     null|\n|  1|   4507|   21|   911.93|      0|       48|\n|  2|   4405|   38|  7891.37|      1|      587|\n|  3|   8341|   42|    10.56|      1|      999|\n|  4|   7777|   56|  4939.32|   null|     1233|\n|  5|   6666|   98|   1234.0|      0|     1234|\n+---+-------+-----+---------+-------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "df_B.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2861c520-4d94-4ebf-955f-5e21d8272e1a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+-----+\n|cust_id|c_score_C|balance_C|age_C|\n+-------+---------+---------+-----+\n|   4232|     null|    58.58|   23|\n|   9947|      687|  3400.21|   66|\n|   8888|      951|    78.29|   18|\n|   6666|      543|    435.0|   97|\n+-------+---------+---------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df_C.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a883b7a3-c8ad-4c95-b37c-09b908403011",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Step 2\n",
    "\n",
    "It is ensured that each customer has a `cust_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58fb7b9f-8fc3-4835-85f8-aee82bede7a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_A = df_A.filter(df_A.cust_id.isNotNull())\n",
    "df_B = df_B.filter(df_B.cust_id.isNotNull())\n",
    "df_C = df_C.filter(df_C.cust_id.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2d73adb-1e3a-4a0d-8155-af4820cd85b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---------+-------+------+-----+\n|idx|cust_id|balance_A|churn_A|name_A|age_A|\n+---+-------+---------+-------+------+-----+\n|  1|   1769|  6421.79|      0|  Dave|   30|\n|  2|   8341|   1137.2|      1|   Bob|   42|\n|  3|   4507|   911.93|      0|  Jess|   21|\n|  5|   4405|  7891.37|   null|  Andy|   38|\n|  6|   6666|   1234.0|      0|  null|   99|\n+---+-------+---------+-------+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df_A.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cd20618-3a1c-4566-93cb-b2dce0c00af6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Step 3\n",
    "\n",
    "It is assumed that `cust_id`\n",
    "- exists.\n",
    "- is unique.\n",
    "\n",
    "That is, `cust_id` is assumed to be a valid primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed166084-4d02-437c-b294-84958baa99ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "full_joined_df = df_A.join(df_B, on='cust_id', how='full').join(df_C, on='cust_id', how='full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38239831-ffca-4fc3-a541-a8d7b9051e07",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Step 4a (Observation)\n",
    "\n",
    "Data validation. To find an idea on how to approach this, note that data in `full_joined_df` can be validated row-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e4e9848-f582-4139-b983-66b57fb5ce70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+---------+-------+------+-----+----+-----+---------+-------+---------+---------+---------+-----+\n|cust_id| idx|balance_A|churn_A|name_A|age_A| idx|age_B|balance_B|churn_B|c_score_B|c_score_C|balance_C|age_C|\n+-------+----+---------+-------+------+-----+----+-----+---------+-------+---------+---------+---------+-----+\n|   1769|   1|  6421.79|      0|  Dave|   30|   0|   30|  6421.79|      0|     null|     null|     null| null|\n|   4232|null|     null|   null|  null| null|null| null|     null|   null|     null|     null|    58.58|   23|\n|   4405|   5|  7891.37|   null|  Andy|   38|   2|   38|  7891.37|      1|      587|     null|     null| null|\n|   4507|   3|   911.93|      0|  Jess|   21|   1|   21|   911.93|      0|       48|     null|     null| null|\n|   6666|   6|   1234.0|      0|  null|   99|   5|   98|   1234.0|      0|     1234|      543|    435.0|   97|\n|   7777|null|     null|   null|  null| null|   4|   56|  4939.32|   null|     1233|     null|     null| null|\n|   8341|   2|   1137.2|      1|   Bob|   42|   3|   42|    10.56|      1|      999|     null|     null| null|\n|   8888|null|     null|   null|  null| null|null| null|     null|   null|     null|      951|    78.29|   18|\n|   9947|null|     null|   null|  null| null|null| null|     null|   null|     null|      687|  3400.21|   66|\n+-------+----+---------+-------+------+-----+----+-----+---------+-------+---------+---------+---------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "full_joined_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2408cfc-e059-44c5-a88c-930ce93deeba",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Each attribute can be selected, and each valid row will have one non-null value at most. Rows with more than one non-null value is a data clash, and must be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61ded7cc-7739-44cd-a0a6-66f1f47fb82b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+---------+--------------+\n|cust_id|balance_A|balance_B|balance_C|distinct_count|\n+-------+---------+---------+---------+--------------+\n|   1769|  6421.79|  6421.79|     null|             1|\n|   4232|     null|     null|    58.58|             1|\n|   4405|  7891.37|  7891.37|     null|             1|\n|   4507|   911.93|   911.93|     null|             1|\n|   6666|   1234.0|   1234.0|    435.0|             2|\n|   7777|     null|  4939.32|     null|             1|\n|   8341|   1137.2|    10.56|     null|             2|\n|   8888|     null|     null|    78.29|             1|\n|   9947|     null|     null|  3400.21|             1|\n+-------+---------+---------+---------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "full_joined_df.select(['cust_id']+[c for c in full_joined_df.columns if 'balance' in c]).withColumn(\n",
    "    'distinct_count',\n",
    "    F.size(F.array_distinct(\n",
    "        F.expr('filter(array(balance_A, balance_B, balance_C), x -> x IS NOT NULL)')\n",
    "    ))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95364202-76db-451b-b448-96a64c45dfac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Searching `full_joined_df`, it is seen that customers `8341` and `6666` have outliers in their balances. Counting distinct values can be done for each attribute, and customers can be validated if all the distinct counts are 0 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f32c956-fec5-4412-a6bd-35bc277643d3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Step 4b (Implementation)\n",
    "\n",
    "Now the observation is implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df534cbb-1d66-4139-9a6f-650ecf936045",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outer_joined = full_joined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89f37484-b1a7-4056-ab38-87a97af14af3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Count the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "206ad754-0384-40d1-afc5-c56b0aac22f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for column_name in target_df.columns[1:]:\n",
    "    columns = [c for c in outer_joined.columns if column_name in c]\n",
    "    quoted_columns = [f\"`{c}`\" for c in columns]\n",
    "    temp = ', '.join(quoted_columns)\n",
    "    distinct_count = F.size(\n",
    "        F.array_distinct(\n",
    "            F.expr(f\"filter(array({temp}), x -> x IS NOT NULL)\")\n",
    "        )\n",
    "    )\n",
    "    outer_joined = outer_joined.withColumn(\n",
    "        f'valid_{column_name}',\n",
    "        F.when(distinct_count > 1, F.lit(False))\n",
    "         .otherwise(F.lit(True))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "576341f1-c7d6-413b-96e5-c6e6940bb97d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Filter for valid rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bed0811-ef07-42e0-ae8a-cfa1abe9727d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "boolean_columns = [c for c in outer_joined.columns if 'valid' in c]\n",
    "filter_cond = (F.col(column) == True for column in boolean_columns)\n",
    "filter_expr = reduce(lambda x, y: x & y, filter_cond)\n",
    "outer_joined = outer_joined.filter(filter_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31da21b3-c182-4025-80f3-cad68884b881",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+---------+-------+------+-----+----+-----+---------+-------+---------+---------+---------+-----+----------+---------+-------------+-------------+-----------+\n|cust_id| idx|balance_A|churn_A|name_A|age_A| idx|age_B|balance_B|churn_B|c_score_B|c_score_C|balance_C|age_C|valid_name|valid_age|valid_balance|valid_c_score|valid_churn|\n+-------+----+---------+-------+------+-----+----+-----+---------+-------+---------+---------+---------+-----+----------+---------+-------------+-------------+-----------+\n|   1769|   1|  6421.79|      0|  Dave|   30|   0|   30|  6421.79|      0|     null|     null|     null| null|      true|     true|         true|         true|       true|\n|   4232|null|     null|   null|  null| null|null| null|     null|   null|     null|     null|    58.58|   23|      true|     true|         true|         true|       true|\n|   4405|   5|  7891.37|   null|  Andy|   38|   2|   38|  7891.37|      1|      587|     null|     null| null|      true|     true|         true|         true|       true|\n|   4507|   3|   911.93|      0|  Jess|   21|   1|   21|   911.93|      0|       48|     null|     null| null|      true|     true|         true|         true|       true|\n|   7777|null|     null|   null|  null| null|   4|   56|  4939.32|   null|     1233|     null|     null| null|      true|     true|         true|         true|       true|\n|   8888|null|     null|   null|  null| null|null| null|     null|   null|     null|      951|    78.29|   18|      true|     true|         true|         true|       true|\n|   9947|null|     null|   null|  null| null|null| null|     null|   null|     null|      687|  3400.21|   66|      true|     true|         true|         true|       true|\n+-------+----+---------+-------+------+-----+----+-----+---------+-------+---------+---------+---------+-----+----------+---------+-------------+-------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "outer_joined.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c1a4cbd-4733-4263-9663-60b12811e50a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Construct the target dataframe by coalescing values from the filtered outerjoined table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "499e79be-e96d-43c9-862a-efdf8c4f05b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target_schema = {field.name: field.dataType for field in target_df.schema.fields}\n",
    "for column_name in target_df.columns[1:]:\n",
    "    matching_columns = [c for c in outer_joined.columns if c.startswith(column_name)]\n",
    "    casted_columns = [F.col(c).cast(target_schema[column_name]) for c in matching_columns]\n",
    "    outer_joined = outer_joined.withColumn(column_name, F.coalesce(*casted_columns))\n",
    "final_columns = [F.col(c) for c in target_df.columns]\n",
    "final_df = outer_joined.select(*final_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7639b61-9c35-4aca-a606-a2811fa25d13",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b33d995-72ca-406e-bf27-218e3b5b2431",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+---+-------+-------+-----+\n|cust_id|name|age|balance|c_score|churn|\n+-------+----+---+-------+-------+-----+\n|   1769|Dave| 30|6421.79|   null|    0|\n|   4232|null| 23|  58.58|   null| null|\n|   4405|Andy| 38|7891.37|    587|    1|\n|   4507|Jess| 21| 911.93|     48|    0|\n|   7777|null| 56|4939.32|   1233| null|\n|   8888|null| 18|  78.29|    951| null|\n|   9947|null| 66|3400.21|    687| null|\n+-------+----+---+-------+-------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "final_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a1a80b6-00e3-4af8-8ea3-c9753159b754",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The resulting table is exactly the result that we set out to find!"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Data Pipeline Model",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
